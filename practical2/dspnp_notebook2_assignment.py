# -*- coding: utf-8 -*-
"""DSPNP_notebook2_assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sSlTWymfP2Oj-5Ebu0CFBu_HBEhAbqdE

#  Assignment: Handwritten digits dataset

The dataset that you will use in this assignment is the [*digits* dataset](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) which contains $1797$ images of $10$ hand-written digits. The digits have been preprocessed so that $32 \times 32$ bitmaps are divided into non-overlapping blocks of $4 \times 4$ and the number of on pixels are counted in each block. This generates an input matrix of $8 \times 8$ where each element is an integer in the range of $[0, ..., 16]$. This reduces dimensionality and gives invariance to small distortions.

For further information on NIST preprocessing routines applied to this data, see M. D. Garris, J. L. Blue, G. T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C. L. Wilson, *NIST Form-Based Handprint Recognition System*, NISTIR 5469, 1994.

As before, use the `sklearn`'s data uploading routines to load the dataset and get the data fields.

**Task:** For the rest of the practical, apply the data preprocessing techniques, implement and evaluate the classification models on the digits dataset using the steps that you applied above to the iris dataset.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd

import matplotlib
from matplotlib import pyplot as plt
# %matplotlib inline

"""## Uploading the dataset"""

# Uploading the dataset

from sklearn import datasets
digits = datasets.load_digits()
print(list(digits.keys()))
print(digits.target_names)

X, y = digits["data"], digits["target"]
X.shape

y.shape

some_digit = X[3]
print("Label: {}".format(y[3]))
some_digit_image = some_digit.reshape(8, 8)

plt.imshow(some_digit_image, cmap=matplotlib.cm.binary, interpolation="nearest")
plt.axis("off")
plt.show()

np.random.seed(1)

"""Looking at which pixels are the most important for each digit by computing the average value at that pixel across all the images.

An example for digit 3:
"""

np.random.seed(1)
ix_3 = np.where(digits["target"] == 3)
X_3 = X[ix_3]
X_3.shape

# Average value per pixel
X_3_avg = np.sum(X_3, axis=0) / X_3.shape[0]
X_3_avg.shape

fig = plt.figure(figsize=(3,3))
plt.imshow(X_3_avg.reshape((8, 8)))
plt.axis('off')
plt.show()

"""Now for all digits"""

fig=plt.figure(figsize=(10, 4))

index = 1
columns = 5
rows = 2

for i in range(1, 11):
    X_i = X[np.where(digits['target'] == i-1)]
    X_i_avg = np.average(X_i, axis=0)
    fig.add_subplot(rows, columns, i)
    plt.axis('off')
    plt.imshow(X_i_avg.reshape((8,8)))


plt.show()

"""Difference between the given digit and the all the other digits combined, i.e. which parts of the image for a specific digit are extra important compared to all the other images. For example, 0 is special because, unlike other images, it has a hole in the middle so the middle of the image has higher-valued (lighter) pixels relative to the other digits."""

fig=plt.figure(figsize=(10, 4))

index = 1
columns = 5
rows = 2

for i in range(1, 11):
    X_i = X[np.where(digits['target'] == i-1)]
    X_i_avg = np.average(X_i, axis=0)
    X_i_diff = X_i_avg - np.average(X[np.where(digits['target'] != i-1)], axis=0)
    fig.add_subplot(rows, columns, i)
    plt.axis('off')
    plt.imshow(X_i_diff.reshape((8,8)))


plt.show()

"""## Splitting the data into training and test subsets

Apply stratified random splitting by digit so that each digit is equally represented in train and test sets.
"""

from sklearn.model_selection import StratifiedShuffleSplit

split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=2)
split.get_n_splits(X, y)
print(split)       

for train_index, test_index in split.split(X, y):
    print("TRAIN:", len(train_index), "TEST:", len(test_index))
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)

"""This returns the following proportions of each digit."""

import pandas as pd

def subset_proportions(subset):
    props = {}
    for value in set(subset):
        data_value = [i for i in subset if i==value]
        props[value] = len(data_value) / len(subset)
    return props

   
compare_props = pd.DataFrame({
    "Overall": subset_proportions(digits["target"]),
    "Stratified tr": subset_proportions(y_train),
    "Stratified ts": subset_proportions(y_test),
})
compare_props["Strat. tr %error"] = 100 * compare_props["Stratified tr"] / compare_props["Overall"] - 100
compare_props["Strat. ts %error"] = 100 * compare_props["Stratified ts"] / compare_props["Overall"] - 100

compare_props.sort_index()

"""## Binary classification

### Perceptron

Creating 10 perceptrons for the 10 classes of digits.
"""

# Create binary labels to separate each digit
y_train_digit = [y_train == i for i in digits.target_names]
y_test_digit = [y_test == i for i in digits.target_names]
y_train_digit

# Fit each digit's perceptron
from sklearn.linear_model import SGDClassifier

sgds = []
for i in digits.target_names:
  sgd = SGDClassifier(max_iter=5, tol=None, random_state=42,
                   loss="perceptron", eta0=1, learning_rate="constant", penalty=None)
  sgd.fit(X_train, y_train_digit[i])
  sgds.append(sgd)

"""### Logistic regression"""

from sklearn.linear_model import LogisticRegression

log_regs = []
for i in digits.target_names:
  log_reg = LogisticRegression()
  log_reg.fit(X_train, y_train_digit[i])
  log_regs.append(log_reg)

"""### Naive Bayes"""

from sklearn.naive_bayes import GaussianNB

gnbs = []
for i in digits.target_names:
  gnb = GaussianNB() 
  gnb.fit(X_train, y_train_digit[i])
  gnbs.append(gnb)

"""## Evaluation"""

from sklearn.model_selection import cross_val_score

import warnings
warnings.filterwarnings('ignore')

log_reg_scores = []
gnb_scores = []
sgd_scores = []

for i in digits.target_names:
  print(i)
  log_reg_score = cross_val_score(log_regs[i], X_train, y_train_digit[i], cv=5, scoring="accuracy")
  gnb_score = cross_val_score(gnbs[i], X_train, y_train_digit[i], cv=5, scoring="accuracy")
  sgd_score = cross_val_score(sgds[i], X_train, y_train_digit[i], cv=5, scoring="accuracy")
  log_reg_scores.append(log_reg_score)
  gnb_scores.append(gnb_score)
  sgd_scores.append(sgd_score)
  print(log_reg_score)
  print(gnb_score)
  print(sgd_score)
  print()

"""### Baselines"""

from sklearn.base import BaseEstimator

class NotXClassifier(BaseEstimator):
    def fit(self, X, y=None):
        pass
    def predict(self, X):
        return np.zeros((len(X), 1), dtype=bool)

not_digit_clf = NotXClassifier()
not_digit_clf_scores = []
for i in digits.target_names:
  score = cross_val_score(not_digit_clf, X_train, y_train_digit[i], cv=5, scoring="accuracy")
  print(score)
  not_digit_clf_scores.append(score)

fig=plt.figure(figsize=(15, 5))
fig.subplots_adjust(hspace=0.2, wspace=0.4)

index = 1
columns = 5
rows = 2

for i in range(1, 11):
  ax = fig.add_subplot(rows, columns, i)
  index += 1
  ax.bar(0, not_digit_clf_scores[i-1])
  ax.bar(1, log_reg_scores[i-1])
  ax.bar(2, gnb_scores[i-1])
  ax.bar(3, sgd_scores[i-1])
  ax.title.set_text(i-1)
  ax.tick_params(axis='x', bottom=False, labelbottom=False)
    
fig.legend(('Baseline', 'LogReg', 'GaussianNB', 'SGD'))
plt.show()

"""### Confusion matrices

#### Logistic regression
"""

from sklearn.model_selection import cross_val_predict
from sklearn.metrics import confusion_matrix

fig=plt.figure(figsize=(15, 5))
fig.subplots_adjust(hspace=0.2, wspace=0.4)

index = 1
columns = 5
rows = 2


for i in range(1, 11):
  y_train_pred = cross_val_predict(log_regs[i-1], X_train, y_train_digit[i-1], cv=5)
  fig.add_subplot(rows, columns, i)
  print(confusion_matrix(y_train_digit[i-1], y_train_pred))
  plt.axis('off')
  plt.title(i-1)
  plt.imshow(confusion_matrix(y_train_digit[i-1], y_train_pred))
  index += 1


plt.show()

"""### Precision/Recall

#### Logistic regression
"""

from sklearn.metrics import precision_score, recall_score, f1_score

for i in digits.target_names:
  print(i)
  y_train_pred = cross_val_predict(log_regs[i], X_train, y_train_digit[i], cv=5)
  print(precision_score(y_train_digit[i], y_train_pred), 
        recall_score(y_train_digit[i], y_train_pred),
        f1_score(y_train_digit[i], y_train_pred))
  print()

"""We could compare this to the approach with Gaussian Naive Bayes which has the lowest scores.

### Gaussian Naive Bayes
"""

fig=plt.figure(figsize=(15, 5))
fig.subplots_adjust(hspace=0.2, wspace=0.4)

index = 1
columns = 5
rows = 2


for i in range(1, 11):
  y_train_pred = cross_val_predict(gnbs[i-1], X_train, y_train_digit[i-1], cv=5)
  fig.add_subplot(rows, columns, i)
  plt.axis('off')
  plt.title(i-1)
  plt.imshow(confusion_matrix(y_train_digit[i-1], y_train_pred))
  index += 1

plt.show()

"""The confusion visibly reveals the much higher instances of misclassifications compared to the logistic regression approach. For example, digit 5 has more false positives (green) than true positives (blue), indicating that Gaussian Naive Bayes is more likely to say that the digit is 5 when it is not."""

for i in digits.target_names:
  print(i)
  y_train_pred = cross_val_predict(gnbs[i], X_train, y_train_digit[i], cv=5)
  print(precision_score(y_train_digit[i], y_train_pred), 
        recall_score(y_train_digit[i], y_train_pred),
        f1_score(y_train_digit[i], y_train_pred))
  print()

"""In general, Gaussian Naive Bayes seems to have a much higher *false positive rate* (hence lower *specificity*), which could be seen from comparing the ROC-AUC curves of the two types of classifiers.

### ROC curves
"""

from sklearn.metrics import roc_curve, roc_auc_score

def plot_roc_curve(fpr, tpr, label=None):
    plt.plot(fpr, tpr, linewidth=2, label=label)
    plt.plot([0, 1], [0, 1], "k--")
    plt.axis([0, 1, 0, 1.01])
    plt.xlabel("False positive rate (fpr)")
    plt.ylabel("True positive rate (tpr)")

fig=plt.figure(figsize=(18, 6))
fig.subplots_adjust(hspace=0.4, wspace=0.4)

index = 1
columns = 5
rows = 2


for i in range(1, 11):
  y_probas_gnb = cross_val_predict(gnbs[i-1], X_train, y_train_digit[i-1], cv=3, method="predict_proba")
  y_probas_log_reg = cross_val_predict(log_regs[i-1], X_train, y_train_digit[i-1], cv=3, method="predict_proba")

  y_scores_gnb = y_probas_gnb[:, 1] # score = proba of the positive class
  y_scores_log_reg = y_probas_log_reg[:, 1]

  fpr_gnb, tpr_gnb, thresholds_gnb = roc_curve(y_train_digit[i-1], y_scores_gnb)
  fpr_log_reg, tpr_log_reg, thresholds_log_reg = roc_curve(y_train_digit[i-1], y_scores_log_reg)
  print(i-1)
  print(roc_auc_score(y_train_digit[i-1], y_scores_log_reg), roc_auc_score(y_train_digit[i-1], y_scores_gnb))
  
  fig.add_subplot(rows, columns, i)
  plt.plot(fpr_log_reg, tpr_log_reg, "b:", label="Logistic Regression")
  plot_roc_curve(fpr_gnb, tpr_gnb, "Gaussian Naive Bayes")

  plt.title(i-1)
  index += 1

plt.legend(loc="lower right")
plt.show()

"""The above ROC curves show that both types of classifiers have similar performance in detecting digits like 0, 4 and 6, and Gaussian Naive Bayes has relatively low performance compared to the logistic regression in digits like 5 and 8—corresponding to discrepancies in the confusion matrix.

Logistic regression seems to have perfect area under curve for digit 2.

### Kernel trick
"""

from sklearn.kernel_approximation import RBFSampler

gnb_rbfs = []
rbf_features = RBFSampler(gamma=1, random_state=42)
X_train_features = rbf_features.fit_transform(X_train)
print(X_train.shape, "->", X_train_features.shape)

for i in digits.target_names:
  gnb_rbf = GaussianNB()
  gnb_rbf.fit(X_train_features, y_train_digit[i]) 
  print(gnb_rbf.score(X_train_features, y_train_digit[i]))
  gnb_rbfs.append(gnb_rbf)

"""Comparing the ROC curves for standard and kernel-transformed Gaussian Naive Bayes,"""

fig=plt.figure(figsize=(18, 6))
fig.subplots_adjust(hspace=0.4, wspace=0.4)

index = 1
columns = 5
rows = 2

from sklearn.metrics import roc_auc_score

for i in range(1, 11):
  y_probas_gnb_rbf = cross_val_predict(gnb_rbfs[i-1], X_train, y_train_digit[i-1], cv=3, method="predict_proba")
  y_scores_gnb_rbf = y_probas_gnb_rbf[:, 1]
  fpr_gnb_rbf, tpr_gnb_rbf, thresholds_gnb_rbf = roc_curve(y_train_digit[i-1], y_scores_gnb_rbf)
  print(i-1)
  print(roc_auc_score(y_train_digit[i-1], y_scores_gnb_rbf), roc_auc_score(y_train_digit[i-1], y_scores_gnb))
  
  fig.add_subplot(rows, columns, i)
  plt.plot(fpr_gnb_rbf, tpr_gnb_rbf, "b:", label="Kernel Gaussian NB")
  plot_roc_curve(fpr_gnb, tpr_gnb, "Gaussian NB")

  plt.title(i-1)
  index += 1

plt.legend()
plt.show()

"""It seems like performance is varied and depends on the digit, e.g. improved for 0, 4 and 6 (where it was already relatively good) but got even worse for digit 8 (which had already relatively bad performance).

## Multi-class Classification
"""

from sklearn.multiclass import OneVsOneClassifier
from sklearn.kernel_approximation import RBFSampler

# One vs All SGD Classifier
sgd = SGDClassifier(max_iter=5, random_state=42, loss="perceptron", 
                                           eta0=1, learning_rate="constant", penalty=None)
sgd.fit(X_train, y_train)

# One vs All Gaussian NB Classifier
gnb = GaussianNB()
gnb.fit(X_train, y_train)

# One vs One SGD Classifier
rbf_features = RBFSampler(gamma=1, n_components=100, random_state=42)
X_train_features = rbf_features.fit_transform(X_train)

ovo_sgd = OneVsOneClassifier(SGDClassifier(max_iter=5, random_state=42, loss="perceptron", 
                                           eta0=1, learning_rate="constant", penalty=None))
ovo_sgd.fit(X_train, y_train)

# One vs One Gaussian NB Classifier
ovo_gnb = OneVsOneClassifier(GaussianNB())
ovo_gnb.fit(X_train, y_train)

"""Looking at untransformed performance first,"""

print(cross_val_score(sgd, X_train, y_train, cv=5, scoring="accuracy"))
print(cross_val_score(gnb, X_train, y_train, cv=5, scoring="accuracy"))
print(cross_val_score(ovo_sgd, X_train, y_train, cv=5, scoring="accuracy"))
print(cross_val_score(ovo_gnb, X_train, y_train, cv=5, scoring="accuracy"))

"""Now with applied transformations,"""

from sklearn.preprocessing import StandardScaler, MinMaxScaler

print(cross_val_score(sgd, X_train_features, y_train, cv=5, scoring="accuracy"))
print(cross_val_score(gnb, X_train_features, y_train, cv=5, scoring="accuracy"))
print(cross_val_score(ovo_sgd, X_train_features, y_train, cv=5, scoring="accuracy"))
print(cross_val_score(ovo_gnb, X_train_features, y_train, cv=5, scoring="accuracy"))

"""Now the performance is very poor for all classifiers. This can be further visualised with the confusion matrix:"""

y_train_pred_sgd = cross_val_predict(sgd, X_train_features, y_train, cv=3)
y_train_pred_gnb = cross_val_predict(gnb, X_train_features, y_train, cv=3)

y_train_pred_ovo_sgd = cross_val_predict(ovo_sgd, X_train_features, y_train, cv=3)
y_train_pred_ovo_gnb = cross_val_predict(ovo_gnb, X_train_features, y_train, cv=3)


conf_mxs = [confusion_matrix(y_train, y_train_pred_sgd),
            confusion_matrix(y_train, y_train_pred_gnb),
            confusion_matrix(y_train, y_train_pred_ovo_sgd),
            confusion_matrix(y_train, y_train_pred_ovo_gnb)]
conf_mxs_labels = ['sgd', 'gnb', 'ovo_sgd', 'ovo_gnb']

fig=plt.figure(figsize=(8, 8))
fig.subplots_adjust(hspace=0.4, wspace=0.4)

index = 0
columns = 2
rows = 2

for i in range(1, columns*rows+1):
  fig.add_subplot(rows, columns, i)
  plt.imshow(conf_mxs[index], cmap = "jet")
  plt.title(conf_mxs_labels[index])
  index += 1

plt.show()

"""Looks like the classifiers are pretty confused. :/ 

On the untransformed data,
"""

y_train_pred_sgd = cross_val_predict(sgd, X_train, y_train, cv=3)
y_train_pred_gnb = cross_val_predict(gnb, X_train, y_train, cv=3)

y_train_pred_ovo_sgd = cross_val_predict(ovo_sgd, X_train, y_train, cv=3)
y_train_pred_ovo_gnb = cross_val_predict(ovo_gnb, X_train, y_train, cv=3)


conf_mxs = [confusion_matrix(y_train, y_train_pred_sgd),
            confusion_matrix(y_train, y_train_pred_gnb),
            confusion_matrix(y_train, y_train_pred_ovo_sgd),
            confusion_matrix(y_train, y_train_pred_ovo_gnb)]
conf_mxs_labels = ['sgd', 'gnb', 'ovo_sgd', 'ovo_gnb']

fig=plt.figure(figsize=(8, 8))
fig.subplots_adjust(hspace=0.4, wspace=0.4)

index = 0
columns = 2
rows = 2

for i in range(1, columns*rows+1):
  fig.add_subplot(rows, columns, i)
  plt.imshow(conf_mxs[index], cmap = "jet")
  plt.title(conf_mxs_labels[index])
  index += 1

plt.show()

"""So in the digits dataset we got the better performance when not transforming the features with the `RBFSampler`, with OvO SGD performing the best.

Further scaling untransformed data,
"""

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))

y_train_pred_sgd = cross_val_predict(sgd, X_train_scaled, y_train, cv=3)
y_train_pred_gnb = cross_val_predict(gnb, X_train_scaled, y_train, cv=3)

y_train_pred_ovo_sgd = cross_val_predict(ovo_sgd, X_train_scaled, y_train, cv=3)
y_train_pred_ovo_gnb = cross_val_predict(ovo_gnb, X_train_scaled, y_train, cv=3)


conf_mxs = [confusion_matrix(y_train, y_train_pred_sgd),
            confusion_matrix(y_train, y_train_pred_gnb),
            confusion_matrix(y_train, y_train_pred_ovo_sgd),
            confusion_matrix(y_train, y_train_pred_ovo_gnb)]
conf_mxs_labels = ['sgd', 'gnb', 'ovo_sgd', 'ovo_gnb']

fig=plt.figure(figsize=(8, 8))
fig.subplots_adjust(hspace=0.4, wspace=0.4)

index = 0
columns = 2
rows = 2

for i in range(1, columns*rows+1):
  fig.add_subplot(rows, columns, i)
  plt.imshow(conf_mxs[index], cmap = "jet")
  plt.title(conf_mxs_labels[index])
  index += 1

plt.show()

"""The performance seems to be slightly worse as the values in diagonal take lower values.

## Evaluating on test set

Evaluating on the untransformed features,
"""

from sklearn.metrics import accuracy_score
from sklearn.kernel_approximation import RBFSampler

# rbf_features = RBFSampler(gamma=1, random_state=42)
# X_test_features = rbf_features.fit_transform(X_train)

# X_test_features_scaled = scaler.fit_transform(X_test_features.astype(np.float64))

print('OvA SGD: {}'.format(accuracy_score(y_test, sgd.predict(X_test))))
print('OvA GNB: {}'.format(accuracy_score(y_test, gnb.predict(X_test))))
print('OvO SGD: {}'.format(accuracy_score(y_test, ovo_sgd.predict(X_test))))
print('OvO GNB: {}'.format(accuracy_score(y_test, ovo_gnb.predict(X_test))))

"""OvO SGD is the best performing again as it was on the cross-validation of the training dataset."""

y_test_pred_sgd = sgd.predict(X_test)
y_test_pred_gnb = gnb.predict(X_test)

y_test_pred_ovo_sgd = ovo_sgd.predict(X_test)
y_test_pred_ovo_gnb = ovo_sgd.predict(X_test)


conf_mxs = [confusion_matrix(y_test, y_test_pred_sgd),
            confusion_matrix(y_test, y_test_pred_gnb),
            confusion_matrix(y_test, y_test_pred_ovo_sgd),
            confusion_matrix(y_test, y_test_pred_ovo_gnb)]
conf_mxs_labels = ['sgd', 'gnb', 'ovo_sgd', 'ovo_gnb']

fig=plt.figure(figsize=(8, 8))
fig.subplots_adjust(hspace=0.4, wspace=0.4)

index = 0
columns = 2
rows = 2

for i in range(1, columns*rows+1):
  fig.add_subplot(rows, columns, i)
  plt.imshow(conf_mxs[index], cmap = "jet")
  plt.title(conf_mxs_labels[index])
  index += 1

plt.show()