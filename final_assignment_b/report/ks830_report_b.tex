\documentclass[10pt, twocolumn]{article}
%% Language and font encodings
\usepackage[british]{babel}

\usepackage[T1]{fontenc}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=3cm,left=2cm,right=2cm]{geometry}

\setlength{\columnsep}{12pt}

\usepackage{amsmath,amssymb}  % Better maths support & more symbols
\usepackage{bm}  % Define \bm{} to use bold math fonts
\usepackage{mathtools}

\usepackage[shortlabels]{enumitem}
\usepackage[normalem]{ulem}

\usepackage[utf8]{inputenc} % Any characters can be typed directly from the keyboard, eg ÃÂ©ÃÂ§ÃÂ±
\DeclareUnicodeCharacter{2212}{-}

\usepackage{parskip}
\usepackage{graphicx}
\graphicspath{{figures/}}

\usepackage{subcaption}

\usepackage{tabularx}

\usepackage{hyperref}
\urlstyle{same}

% \renewcommand{\cfttoctitlefont}{\fontsize{12}{15}\selectfont\bfseries}
% \renewcommand\cftsecfont{\small}
% \renewcommand\cftsecafterpnum{\vskip 0pt}
% \renewcommand\cftsecpagefont{\small}

\usepackage{pdfsync}  % enable tex source and pdf output synchronicity


\usepackage{fancyhdr}
\fancypagestyle{first}{
	\fancyhf{} % clear all header and footers
	\renewcommand{\headrulewidth}{0pt} % remove the line
	\setlength{\footskip}{50pt}
	\fancyfoot[C]{\thepage}

}

\fancypagestyle{plain}{
	\fancyhf{} % clear all header and footers
	% \renewcommand{\headrulewidth}{0pt} % remove the line
	% \setlength{\headheight}{5pt}
	\setlength{\footskip}{50pt}
	\fancyfoot[C]{\thepage}
	\fancyhead[C]{\textbf{\svsubject—\svshortsubject{}\ (ks830)}}
}

\def\svauthor{Kamilė Stankevičiūtė (\texttt{ks830})}
\def\college{Gonville \& Caius College}
\def\svsubject{Data Science: Principles and Practice}
\def\svshortsubject{Final Assignment B}

\usepackage{pdfpages}
\usepackage{float}
\usepackage{stfloats}

% \usepackage{minted}
% \usemintedstyle{colorful}

\begin{document}

\thispagestyle{first}
\pagestyle{plain}
\twocolumn[{
\begin{center}
\LARGE
\textbf{Data Science: Principles and Practice \\ Final Assignment B} \\[4mm]

\large
Kamilė Stankevičiūtė (\texttt{ks830}) \\ Gonville \& Caius College \\[4mm]

% \today % October 2019
\end{center} \vskip10mm}]


\section{Data preparation}

I use the raw data (\textit{diabetic\_data\_original.csv}) of the same medical care record dataset \cite{strack2014dataset} as in Assignment A. The following section describes the changes in preprocessing steps with respect to the previous part of the assignment.

\paragraph{Filtering}
TODO filter out the patients that have less than two encounters per patient.

TODO consider taking only one 

\paragraph{Anonymisation} 
TODO still remove patient/encounter number from the dataset 
TODO I decided to keep multiple copies for the same patient but (make sure that at least the same patient does not get into both training and test set??)

Some patients have multiple encounter records (up to 15 per patient). This might skew the results of further analysis (whether exploration or classification) as models might learn to identify particular patients (through patient number or otherwise). For this reason at most one randomly sampled encounter per patient will be included in further analysis, and patient and encounter numbers removed. 

TODO This leaves ? unique instances.

\paragraph{Missing values} 

TODO which features in the dataset contain missing values and how much 

TODO The dataset has several features with missing values, most notably weight (?\%), payer code (?\%), and medical specialty (?\%). The first two will be excluded from further analysis. I will assume that the values are missing at random and replace them (as well as the other missing categorical feature values) with a separate category. There seems to be no numerical feature values missing.

\paragraph{Unknown values, numerical and categorical features} No changes in processing compared to assignment A.

\paragraph{Feature sets} Since the dataset is larger and the models are generally more powerful, I will train on the full feature set only, leaving feature extraction to the model.

\paragraph{Train and test split} 
TODO stratification: based on patient, hospital (novel contexts), \dots

TODO proportion of train/test split and the numbers in every set. Consider using a validation set.

\paragraph{Hyperparameters} I generally tried to use the default hyperparameters. 

The hyperparameters used for each classifier can be found in \texttt{training.py} script.


\medskip
 
\bibliographystyle{unsrt}
\bibliography{ks830_report_b}

\end{document}