\documentclass[10pt, twocolumn]{article}
%% Language and font encodings
\usepackage[british]{babel}

\usepackage[T1]{fontenc}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=3cm,left=2cm,right=2cm]{geometry}

\setlength{\columnsep}{12pt}

\usepackage{amsmath,amssymb}  % Better maths support & more symbols
\usepackage{bm}  % Define \bm{} to use bold math fonts
\usepackage{mathtools}

\usepackage[shortlabels]{enumitem}
\usepackage[normalem]{ulem}

\usepackage[utf8]{inputenc} % Any characters can be typed directly from the keyboard, eg ÃÂ©ÃÂ§ÃÂ±
\DeclareUnicodeCharacter{2212}{-}

\usepackage{parskip}
\usepackage{graphicx}
\graphicspath{{figures/}}

\usepackage{subcaption}

\usepackage{tabularx}

\usepackage{hyperref}
\urlstyle{same}

% \renewcommand{\cfttoctitlefont}{\fontsize{12}{15}\selectfont\bfseries}
% \renewcommand\cftsecfont{\small}
% \renewcommand\cftsecafterpnum{\vskip 0pt}
% \renewcommand\cftsecpagefont{\small}

\usepackage{pdfsync}  % enable tex source and pdf output synchronicity


\usepackage{fancyhdr}
\fancypagestyle{first}{
	\fancyhf{} % clear all header and footers
	\renewcommand{\headrulewidth}{0pt} % remove the line
	\setlength{\footskip}{50pt}
	\fancyfoot[C]{\thepage}

}

\fancypagestyle{plain}{
	\fancyhf{} % clear all header and footers
	% \renewcommand{\headrulewidth}{0pt} % remove the line
	% \setlength{\headheight}{5pt}
	\setlength{\footskip}{50pt}
	\fancyfoot[C]{\thepage}
	\fancyhead[C]{\textbf{\svsubject—\svshortsubject{}\ (ks830)}}
}

\def\svauthor{Kamilė Stankevičiūtė (\texttt{ks830})}
\def\college{Gonville \& Caius College}
\def\svsubject{Data Science: Principles and Practice}
\def\svshortsubject{Final Assignment B}

\usepackage{pdfpages}
\usepackage{float}
\usepackage{stfloats}

% \usepackage{minted}
% \usemintedstyle{colorful}

\begin{document}

\thispagestyle{first}
\pagestyle{plain}
\twocolumn[{
\begin{center}
\LARGE
\textbf{Data Science: Principles and Practice \\ Final Assignment B} \\[4mm]

\large
Kamilė Stankevičiūtė (\texttt{ks830}) \\ Gonville \& Caius College \\[4mm]

? words
\end{center} \vskip10mm}]


\section{Data preparation}

I use the raw data (\textit{diabetic\_data\_original.csv}) of the same medical care record dataset \cite{strack2014dataset} as in Assignment A. The following section describes the changes in preprocessing steps with respect to the previous Assignment.

\subsection{Selection of training instances}
\paragraph{Filtering}
Due to the nature of the prediction task, only the patients with at least two recorded encounters will be considered. For each patient, I will not use the last encounter as a datapoint because the ground truth (the length of next stay) for it is unknown: either the patient was not readmitted (we did not observe the counterfactual result of how long the stay would have been had the patient been readmitted), or the patient was readmitted but the ground truth for this has not been recorded. 

\paragraph{Multiple examples} To ensure independence of all the examples in the dataset, I will only use a single randomly sampled example per patient.

\paragraph{Multiple readmission} Some patients have recorded follow-on visits even in cases when the readmission outcome is `NO' (e.g. at least 44 patients have been \textit{not readmitted more than once}). Further investigation would be necessary to determine the reason for this in order to handle it correctly—I decided to exclude any no-readmission encounters still left after filtering and length-of-next-stay feature generation. This resulted in ? training instances for ? unique patients.

TODO find number of examples and patients

\subsection{Feature preprocessing}
\paragraph{Anonymisation} As before, the encounter and patient numbers will be removed for training.

\paragraph{Missing values} In the filtered dataset, the features with most values missing are \textit{weight} (98.6\% missing) and \textit{medical specialty} (51.0\%), which I will not use for training. For other features, the missing values were imputed using median or constant strategy for numerical and categorical features respectively.

TODO consider removing drugs adding medical specialty

\paragraph{Numerical and categorical features} Similar to processing in Assignment A: the features are converted to numerical or categorical values based on their meaning. Diagnoses are first grouped into categories to avoid a large number of features with small number of examples. The numerical and categorical features are normalised and one-hot encoded respectively.

\paragraph{Feature sets} Since the dataset is larger and the neural network models more powerful, I will train on the full feature set.

\section{Machine learning set-up}

\subsection{Train and test set split}


TODO \paragraph{(some more specific criterion)} t-SNE has shown...


\subsection{Probabilistic model}

I model the predicted variable (length of next stay) using \textit{zero-truncated Poisson distribution} (ZTP). I truncate the zero because, if the follow-on visit happens, the length of stay must be at least 1, violating the assumptions of the regular Poisson distribution where observations of 0 are possible. The observations $y_i \in \mathbb{N}^+$ are therefore modelled using \[Y_i \sim \mathrm{ZTP}(f_\theta(x_i))\]

where 

\begin{equation}
	\mathbb{P}[Y_i = y_i] = \frac{f_\theta(x_i)^{y_i}}{(e^{f_\theta(x_i)} - 1)y_i!}.
	\label{eq1}
\end{equation}

\paragraph{Loss function} For $M$ examples, parameters $\theta$ maximising the probability of the dataset (expressed as the product of probabilities in (\ref{eq1}) for each observation) minimise the following loss function:

\begin{equation}
	\mathcal{L} = \sum\limits_{i=1}^{M} -y_i \log(f_\theta(x_i)) + \log(e^{f_\theta(x_i)} - 1) + \log(y_i!)
\end{equation}

Following the TensorFlow documentation on Poisson loss function,\footnote{\url{https://www.tensorflow.org/api_docs/python/tf/nn/log_poisson_loss}} to improve efficiency I will be computing the inexact version of this, emitting the constant $\log(y_i!)$ term.


\section{Neural network architecture}

TODO description of neural network architecture


\subsection{Hyperparameters}
I generally tried to use the default hyperparameters. 

The hyperparameters used for each classifier can be found in \texttt{training.ipynb} script.

\section{Results}
TODO table and comparison of results, insights on which model is the best
\subsection{Predictive power}

\subsection{Impact of PCA on training performance}

\section{Evaluation}
TODO Evaluate the predictive power of the best model on the holdout set.


\medskip
 
\bibliographystyle{unsrt}
\bibliography{ks830_report_b}

\end{document}