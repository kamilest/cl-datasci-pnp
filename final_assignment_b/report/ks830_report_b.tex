\documentclass[10pt, twocolumn]{article}
%% Language and font encodings
\usepackage[british]{babel}

\usepackage[T1]{fontenc}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=3cm,left=2cm,right=2cm]{geometry}

\setlength{\columnsep}{12pt}

\usepackage{amsmath,amssymb}  % Better maths support & more symbols
\usepackage{bm}  % Define \bm{} to use bold math fonts
\usepackage{mathtools}

\usepackage[shortlabels]{enumitem}
\usepackage[normalem]{ulem}

\usepackage[utf8]{inputenc} % Any characters can be typed directly from the keyboard, eg ÃÂ©ÃÂ§ÃÂ±
\DeclareUnicodeCharacter{2212}{-}

\usepackage{parskip}
\usepackage{graphicx}
\graphicspath{{figures/}}

\usepackage{subcaption}

\usepackage{tabularx}

\usepackage{hyperref}
\urlstyle{same}

% \renewcommand{\cfttoctitlefont}{\fontsize{12}{15}\selectfont\bfseries}
% \renewcommand\cftsecfont{\small}
% \renewcommand\cftsecafterpnum{\vskip 0pt}
% \renewcommand\cftsecpagefont{\small}

\usepackage{pdfsync}  % enable tex source and pdf output synchronicity


\usepackage{fancyhdr}
\fancypagestyle{first}{
	\fancyhf{} % clear all header and footers
	\renewcommand{\headrulewidth}{0pt} % remove the line
	\setlength{\footskip}{50pt}
	\fancyfoot[C]{\thepage}

}

\fancypagestyle{plain}{
	\fancyhf{} % clear all header and footers
	% \renewcommand{\headrulewidth}{0pt} % remove the line
	% \setlength{\headheight}{5pt}
	\setlength{\footskip}{50pt}
	\fancyfoot[C]{\thepage}
	\fancyhead[C]{\textbf{\svsubject—\svshortsubject{}\ (ks830)}}
}

\def\svauthor{Kamilė Stankevičiūtė (\texttt{ks830})}
\def\college{Gonville \& Caius College}
\def\svsubject{Data Science: Principles and Practice}
\def\svshortsubject{Final Assignment B}

\usepackage{pdfpages}
\usepackage{float}
\usepackage{stfloats}

% \usepackage{minted}
% \usemintedstyle{colorful}

\begin{document}

\thispagestyle{first}
\pagestyle{plain}
\twocolumn[{
\begin{center}
\LARGE
\textbf{Data Science: Principles and Practice \\ Final Assignment B} \\[4mm]

\large
Kamilė Stankevičiūtė (\texttt{ks830}) \\ Gonville \& Caius College \\[4mm]

? words
\end{center} \vskip10mm}]


\section{Data preparation}

I use the raw data (\textit{diabetic\_data\_original.csv}) of the same medical care record dataset \cite{strack2014dataset} as in Assignment A. The following section describes the changes in preprocessing steps with respect to the previous Assignment.

\subsection{Selection of training instances}
The preprocessing steps below resulted in 16515 training instances.

\paragraph{Filtering}
Only the patients with at least two recorded encounters were considered, since the later encounter is required to generate the label for the earlier one. To ensure independence of all examples in the dataset (corresponding to the assumptions of the probabilistic model described below), only one randomly sampled example per patient was used.

\paragraph{Multiple readmission} Taking a closer look at the dataset has shown that some patients have recorded follow-on visits even in cases when the readmission outcome was `NO' (for example, at least 44 patients have been \textit{not readmitted more than once}). Further investigation would be necessary to determine the reason for this (e.g. human error, admission to another hospital,...) in order to handle it correctly. I decided to not sample from any no-readmission encounters (of which after initial filtering there were 490).

\subsection{Feature preprocessing}

The main advantage of using the deep learning tools is their capacity to select the most useful features without manual feature engineering by the analyst. For this reason, the models will be trained in an end-to-end manner on all features, but with the following considerations.

\paragraph{Anonymisation} As before, the encounter and patient numbers were removed at training stage.

\paragraph{Missing values} In the full dataset, the \textit{weight} feature was missing in 98.6\% of instances, so I excluded it from training. For other features, the missing values were imputed using median or constant strategy for numerical and categorical features respectively.

\paragraph{Numerical and categorical features} As before, the features were converted to numerical or categorical values based on their meaning, and further normalised/one-hot encoded for performance reasons. To avoid a large number of sparse features, the diagnoses were compressed to broader categories (e.g. circulatory, respiratory, etc.)


\section{Machine learning set-up}

\subsection{Train and test set split}
With a view to get a more generalisable model, I split the data into qualitatively different sets using a single-component t-SNE projection (perplexity=30), holding out the top 10\% of values for testing, and another 10\% for validation.

\subsection{Probabilistic model}
I model length of next stay using \textit{zero-truncated Poisson distribution} (ZTP). I truncated the zero because, if the follow-on visit happens, the length of stay must be at least 1, violating the assumptions of the regular Poisson distribution where observations of 0 are possible (on the other hand, I still allow predictions of more than 14 days that were not observed in the dataset but in theory should be possible). The observations $y_i \in \mathbb{N}^+$ therefore follow \[Y_i \sim \mathrm{ZTP}(f_\theta(x_i))\]

with probability mass function 

\begin{equation}
	\mathbb{P}[Y_i = y_i | \theta, x_i] = \frac{f_\theta(x_i)^{y_i}}{(e^{f_\theta(x_i)} - 1)y_i!}.
	\label{eq1}
\end{equation}

\paragraph{Loss function} For $M$ examples, parameters $\theta$ maximising the probability of the dataset (expressed as the product of probabilities in (\ref{eq1}) for each observation, assuming independence) minimise the loss function

\begin{equation}
	\mathcal{L} = \sum\limits_{i=1}^{M} -y_i \log(f_\theta(x_i)) + \log(e^{f_\theta(x_i)} - 1) + \log(y_i!)
\end{equation}

which I will use for training, but additionally taking the average (multiplying $\mathcal{L}$ by constant $1/M$).

% Following the TensorFlow documentation on Poisson loss function,\footnote{\url{https://www.tensorflow.org/api_docs/python/tf/nn/log_poisson_loss}} the training can be optimised computing the inexact version of this loss, omitting the constant $\log(y_i!)$ term.


\section{Feedforward neural networks}
Ideally, I wish to be able to predict the length of the follow-on visit for a patient from as little as a single encounter rather than considering the encounter sequences: the original dataset suggests that in majority (54\%) of cases this is indeed the most information that a hospital would have for a patient. (It would also be unclear how to handle the multiple readmission anomalies for encounter sequences to be correct.)

For this task I implement a set of feedforward neural networks.

\subsection{Choice of architecture}
It is tempting to assume that the deeper the neural network, the better, since with more parameters the model has a higher capacity to learn complex feature representations (although taking longer to train). 

To test this assumption and as part of the hyperparameter selection process, I implemented three types of networks, which I will call \textit{deep}, \textit{moderate} and \textit{shallow}, containing around $6\times 10^6$, $3.5\times 10^6$ and 280,000 trainable parameters respectively. Full specification (and training results) can be found in supplementary code. 

\paragraph{Selection process} To compare their typical performance, I trained each of the networks 5 times with early stopping, measuring the average time it takes for the models to converge, and evaluating the training and development set predictions using Pearson's correlation coefficient $r$. I chose this metric as being arguably easier to interpret compared to the custom loss function.

\paragraph{Vanishing gradients} During training, the networks (especially deeper ones) tended to suffer from the vanishing gradients problem, getting stuck with unlucky initialisations (about once in every five runs). Adding batch normalisation between layers and using ReLU activation function resolved this issue, albeit increasing the training times by a factor of 2 to 4 (depending on configuration). 

\begin{table}[]
	\begin{tabularx}{\linewidth}{XXXX}
		\hline
				& \textbf{deep} & \textbf{moderate} & \textbf{shallow}\\ \hline
		time, s     & 276   & 84  & 35 \\
		train $r$ & 0.208 & 0.376 & 0.458 \\
		dev. $r$ & 0.127 & 0.178 & 0.207
		\end{tabularx}
\caption{Mean training time with mean training and development set performance of feedforward neural networks.}\label{g1}
\end{table}

\subsection{Results}
The results, presented in Table \ref{g1}, seem to suggest that deeper networks are, in fact, not always better. With an almost 8-fold increase in training time and lower correlations on both training and development datasets, this particular experiment suggests that deeper networks might, contrary to the assumption, give even worse predictions than the simpler models. 

However, it is curious that even 6 million trainable parameters are not enough to actually (over)fit the training data and give correlations closer to 1 (despite early stopping preventing the model from doing this). Whether this is a fundamental limitation of the dataset (with no useful signal for length of stay prediction), or the lack of hyperparameter optimisation would need a further investigation to determine.

\subsection{Using PCA features as input}
\paragraph{Motivation} One possible way to mitigate the slow training times (especially for the \textit{deep} and \textit{moderate} models) could be the use of PCA components as input features, hopefully saving some time on learning a useful feature representation. At the same time, if PCA is capable to extract the most useful features with its first few components, it could also be used to effectively reduce the input dimensions, in turn reducing the model size and training time. 

\paragraph{Experiments} I test the effectiveness of PCA on neural network training using a similar experimental set-up to the previous section, comparing the training time and development set performance on full feature representation, the PCA features of the same dimensionality and the \textit{reduced} PCA (rPCA) set which only considers the first half of the PCA components. 

TODO reformat the entire thing!!!!! 
\begin{figure*}[htb!]
	\centering
	\includegraphics[width=\textwidth]{figures/pc.png}
	\caption{Impact of PCA feature sets on neural network performance.}\label{pca}
\end{figure*}

\paragraph{Results} 
\begin{table}[]
	\begin{tabularx}{\linewidth}{XXXX}
		\hline
				& \textbf{full} & \textbf{PCA} & \textbf{rPCA}\\ \hline
		deep    & 276   & 237  & 269 \\
		moderate  & 84 & 85 & 88 \\
		shallow & 35 & 20 & 20
		\end{tabularx}
\caption{Mean training time on raw, PCA and reduced PCA feature sets.}\label{g2}
\end{table}

% \begin{table}[]
% 	\begin{tabularx}{\linewidth}{XXXX}
% 		\hline
% 				& \textbf{full} & \textbf{PCA} & \textbf{rPCA}\\ \hline
% 		deep    & 0.127   & 0.168  & 0.116 \\
% 		moderate  & 0.178 & 0.210 & 0.191 \\
% 		shallow & 0.207 & 0.193 & 0.149
% 		\end{tabularx}
% \caption{Mean development set correlations when training on full, PCA and reduced PCA feature sets.}\label{g3}
% \end{table}

The training times using those techniques are shown in Table \ref{g2}. While it is possible that PCA could help with speeding up training, the improvement is not guaranteed – for the moderate network, PCA and rPCA only increased the training time. Even more importantly, PCA could not compensate for the overhead of having a bigger network: the shallow network running on the original feature set is still much faster than the deeper counterparts running on PCA features. The takeaway from this is that, for the purpose of decreasing the training time, we should worry about simplifying the network architecture first, and only then consider any fancy dimensionality reduction techniques.



rPCA seems to be particularly ineffective. Not only did it generally \textit{increase} the training time, but with the information loss from unused low-variance components it also tended to learn less, which could be seen from the points for rPCA in Figure \ref{pca} being below the others.



\section{Evaluation}
The analysis above has shown that the 


\medskip
 
\bibliographystyle{unsrt}
\bibliography{ks830_report_b}

\end{document}