{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "## Step 1: Uploading and inspecting the data\n",
    "\n",
    "* `head()` for getting a first few rows of the dataset, looking at the kind of values\n",
    "* `info()` for getting the description of the data columns\n",
    "* `value_counts()` for counting the instances of each value in categorical variable (maybe would work for floating-point but results would be rather meaningless).\n",
    "* `describe()` for per-feature summary statistics\n",
    "\n",
    "*Questions on interpretation of the dataset from* `describe()`:\n",
    "1. *Interpreting the values.* Not sure what is meant there. The method just returns per-column (feature) summary statistics.\n",
    "2. *Meaning of percentiles.* Percentiles tell how much the distribution is skewed based on how far away the median is from each of the quartiles—`households` column is one such example where distribution is skewed to the left (or tail-heavy?).\n",
    "3. *Handling of missing values.* Documentation says `NaN` by default, which would be skipped in computing statistics (`skipna=True` by default) but would be kept in arrays and propagate through arithmetic calculations. When all values are `NaN` result in automatic statistic calculation is 0.\n",
    "\n",
    "## Step 2: Splitting the data into training and test sets\n",
    "\n",
    "* `np.random.permutation(len(data))` for shuffling the indices and then taking `test_indices` and `train_indices` from this accordingly;\n",
    "  * `data.iloc[train_indices]` for retrieving the data\n",
    "* `from sklearn.model_selection import train_test_split` for automatically splitting the dataset by describing the fraction of test data\n",
    "* stratified sampling to get similar train and test distributions if some features are imbalanced—both distributions will be more representative\n",
    "* binning to limit the number of strata\n",
    "  * `from sklearn.model_selection import StratifiedShuffleSplit`\n",
    "  * split based on a categorical attribute: `split.split(df, df[\"attr\"])`\n",
    "  \n",
    "## Step 3: Exploring the attributes\n",
    "\n",
    "* Visualisation to \n",
    "  * see most informative attributes \n",
    "  * observe correlations with target label using scatter matrix\n",
    "  * observe the need for normalisation/scaling\n",
    "  * can also indicate the artifacts in the data that would need cleaning up\n",
    "* Create extra features\n",
    "\n",
    "## Step 4: Data preparation and transformations of machine learning algorithms\n",
    "\n",
    "Required for:\n",
    "* handling missing values (if any)\n",
    "  * `from sklearn.impute import SimpleImputer`, `imputer.fit(df)`, `imputer.transform`\n",
    "* converting attribute values into numerical format (e.g. transform categorical data into numbers)—*is this actually needed? and it doesn't really make sense for a regression task anyway, especially if there is no 'increasing' ordering to categories*\n",
    "  * numeric value makes the least sense but one-hot encoding using `sklearn.preprocessing.OneHotEncoder`+`sklearn.preprocessing.LabelBinarizer` is better\n",
    "* scaling or normalising data\n",
    "* data transformers and pipelines for connecting transformations together with `fit`/`transform`/`fit_transform`\n",
    "* `FeatureUnion` for connecting together several pipelines (one for each type of feature of categorical/numerical\n",
    "\n",
    "\n",
    "## Step 5: Implementation, evaluation and fine-tuning of a regression model\n",
    "\n",
    "* training, testing, cross-validation—the usual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Experimenting with different steps in the ML pipeline\n",
    "\n",
    "First implement the base of the ML pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline \n",
    "#so that the plot will be displayed in the notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "def load_data(housing_path):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_data(\"housing/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratifying dataset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)\n",
    "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace = True)\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data from labels\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1) # inplace=False\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding derived features (not used for Task 2.1)\n",
    "def add_features(data):\n",
    "    # add the transformed features that you found useful before\n",
    "    data[\"rooms_per_household\"] = data[\"total_rooms\"] / data[\"households\"]\n",
    "    data[\"bedrooms_per_household\"] = data[\"total_bedrooms\"] / data[\"households\"]\n",
    "    data[\"bedrooms_per_rooms\"] = data[\"total_bedrooms\"] / data[\"total_rooms\"]\n",
    "    data[\"population_per_household\"] = data[\"population\"] / data[\"households\"]   \n",
    "    \n",
    "add_features(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Task 2.1, run the cells in the [section below](#2.1) before continuing.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling missing values (not used for Task 2.2)\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "imputer.fit(housing_num)\n",
    "\n",
    "X = imputer.transform(housing_num)\n",
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Task 2.2, run one of the cells in the section below before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling textual and categorical attributes\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder = LabelBinarizer(sparse_output=True)\n",
    "housing_cat_1hot = encoder.fit_transform(housing[\"ocean_proximity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transformation\n",
    "from sklearn.base import TransformerMixin # TransformerMixin allows you to use fit_transform method\n",
    "from sklearn.base import BaseEstimator\n",
    "# BaseEstimator allows you to drop *args and **kwargs from you constructor\n",
    "# and, in addition, allows you to use methods set_params() and get_params()\n",
    "\n",
    "\n",
    "class CustomLabelBinarizer(TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.encoder = LabelBinarizer(*args, **kwargs)\n",
    "    def fit(self, X, y=0):\n",
    "        self.encoder.fit(X)\n",
    "        return self\n",
    "    def transform(self, X, y=0):\n",
    "        return self.encoder.transform(X)\n",
    "    \n",
    "\n",
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "    \n",
    "    \n",
    "rooms_id, bedrooms_id, population_id, household_id = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_rooms = True): # note no *args and **kwargs used this time\n",
    "        self.add_bedrooms_per_rooms = add_bedrooms_per_rooms\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_id] / X[:, household_id]\n",
    "        bedrooms_per_household = X[:, bedrooms_id] / X[:, household_id]\n",
    "        population_per_household = X[:, population_id] / X[:, household_id]\n",
    "        if self.add_bedrooms_per_rooms:\n",
    "            bedrooms_per_rooms = X[:, bedrooms_id] / X[:, rooms_id]\n",
    "            return np.c_[X, rooms_per_household, bedrooms_per_household, \n",
    "                         population_per_household, bedrooms_per_rooms]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, bedrooms_per_household, \n",
    "                         population_per_household]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip the cell below for Task 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_adder = CombinedAttributesAdder()\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)\n",
    "\n",
    "housing_extra_attribs = pd.DataFrame(housing_extra_attribs, columns=list(housing.columns)+\n",
    "                                     [\"rooms_per_household\", \"bedrooms_per_household\", \n",
    "                                      \"population_per_household\", \"bedrooms_per_rooms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "housing_tr_scaled = scaler.fit_transform(housing_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['longitude',\n",
       " 'latitude',\n",
       " 'housing_median_age',\n",
       " 'total_rooms',\n",
       " 'total_bedrooms',\n",
       " 'population',\n",
       " 'households',\n",
       " 'median_income',\n",
       " 'income_cat',\n",
       " 'rooms_per_household',\n",
       " 'bedrooms_per_household',\n",
       " 'bedrooms_per_rooms',\n",
       " 'population_per_household']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['bedrooms_per_household', 'population_per_household', 'rooms_per_household', 'bedrooms_per_rooms'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-aee7258a9d33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mhousing_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrat_train_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"median_house_value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mhousing_prepared\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhousing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0msum\u001b[0m \u001b[0mof\u001b[0m \u001b[0mn_components\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mover\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m         \"\"\"\n\u001b[0;32m--> 912\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parallel_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;31m# All transformers are None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_parallel_func\u001b[0;34m(self, X, y, fit_params, func)\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                                     weight) in enumerate(transformers, 1))\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \"\"\"\n\u001b[1;32m    386\u001b[0m         \u001b[0mlast_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    389\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-219776ee99fc>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[0;32m-> 2934\u001b[0;31m                                                    raise_missing=True)\n\u001b[0m\u001b[1;32m   2935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[1;32m   1353\u001b[0m                           raise_missing}\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[1;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1250\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'loc'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not in index\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['bedrooms_per_household', 'population_per_household', 'rooms_per_household', 'bedrooms_per_rooms'] not in index\""
     ]
    }
   ],
   "source": [
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('label_binarizer', CustomLabelBinarizer()),\n",
    "    ])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])\n",
    "\n",
    "\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# RMSE\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "model = Pipeline([('poly', PolynomialFeatures(degree=3)),\n",
    "                  ('linear', LinearRegression())])\n",
    "\n",
    "model = model.fit(housing_prepared, housing_labels)\n",
    "housing_predictions = model.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desision tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg = tree_reg.fit(housing_prepared, housing_labels)\n",
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "tree_mse = np.sqrt(tree_mse)\n",
    "tree_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "def analyse_cv(model):   \n",
    "    scores = cross_val_score(model, housing_prepared, housing_labels,\n",
    "                             scoring = \"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "    # cross-validation expects utility function (greater is better)\n",
    "    # rather than cost function (lower is better), so the scores returned\n",
    "    # are negative as they are the opposite of MSE\n",
    "    sqrt_scores = np.sqrt(-scores) \n",
    "    print(\"Scores:\", sqrt_scores)\n",
    "    print(\"Mean:\", sqrt_scores.mean())\n",
    "    print(\"Standard deviation:\", sqrt_scores.std())\n",
    "    \n",
    "analyse_cv(tree_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analyse_cv(lin_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=10)\n",
    "analyse_cv(forest_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# specify the range of hyperparameter values for the grid search to try out \n",
    "param_grid = {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]}\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                          scoring=\"neg_mean_squared_error\")\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting feature importance weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "\n",
    "extra_attribs = ['rooms_per_household', 'bedrooms_per_household', 'population_per_household', 'bedrooms_per_rooms']\n",
    "cat_one_hot_attribs = ['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN']\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs # Remove extra_attribs for Task 2.1\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating best model in grid search\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating performance of simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Dropping less informative features\n",
    "<a id='2.1'></a>\n",
    "\n",
    "Instead of adding features with `add_features`, we derive a method for removing less informative features.\n",
    "\n",
    "From the correlation matrix other data analysis, we can try removing features that correlate the least with the label (correlation is closest to 0). Here I set the threshold for removing the feature at `corr` $\\leq 0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_uncorrelated_features(housing, housing_labels, threshold=0.1, inplace=False):\n",
    "    corr_matrix = housing.corrwith(housing_labels)\n",
    "    result = housing.copy()\n",
    "    for feature_name in corr_matrix.keys():\n",
    "        if abs(corr_matrix[feature_name]) <= threshold:\n",
    "            result = result.drop(feature_name, axis=1, inplace=inplace)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_less_features = drop_uncorrelated_features(housing, housing_labels)\n",
    "\n",
    "housing_less_features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the linear regression model: set `housing` to `housing_less_features` and run the cells for training again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = housing_less_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the appropriate cells above returns the following:\n",
    "* linear regression RMSE loss on training set: \n",
    "```\n",
    "73093.17121767759\n",
    "```\n",
    "* polynomial features RMSE loss on training set:\n",
    "```\n",
    "66716.81\n",
    "```\n",
    "* descision tree regression cv scores: \n",
    "```\n",
    "Scores: [84032.49004171 83383.91403853 86911.25618704 84979.91760443\n",
    " 83318.48233598 87035.75651828 81730.25765011 87262.51548502\n",
    " 90687.78902004 81905.17420337]\n",
    "Mean: 85124.75530845068\n",
    "Standard deviation: 2678.7378046054023\n",
    "```\n",
    "* linear regression cv scores:\n",
    "```\n",
    "Scores: [71582.79797914 71558.92841559 72016.97250802 74659.07214991\n",
    " 72930.82717259 75799.57809476 69539.81669857 72886.06082662\n",
    " 76948.76494249 73291.86027004]\n",
    "Mean: 73121.46790577391\n",
    "Standard deviation: 2077.562701780748\n",
    "```\n",
    "* random forest cv scores:\n",
    "```\n",
    "Scores: [62904.45963636 63743.90193276 66368.02660397 66220.97112199\n",
    " 65251.3907331  67133.70330807 62868.39284466 65963.95283889\n",
    " 68337.41046908 66190.1122955 ]\n",
    "Mean: 65498.2321784392\n",
    "Standard deviation: 1717.3381486078756\n",
    "```\n",
    "* final rmse:\n",
    "```\n",
    "61577.52437907747\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The errors can be plotted as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline = {\"lin_rmse\": 68226.597, \n",
    "                   \"poly_rmse\": 51339.164, \n",
    "                   \"tree_cv\": 71844.624, \n",
    "                   \"lin_cv\": 68502.864, \n",
    "                   \"forest_cv\": 52924.711, \n",
    "                   \"final_rmse\": 47796.65\n",
    "                  }\n",
    "less_features = {\"lin_rmse\": 73093.17, \n",
    "                   \"poly_rmse\": 66716.81, \n",
    "                   \"tree_cv\": 85124.76, \n",
    "                   \"lin_cv\": 73121.47, \n",
    "                   \"forest_cv\": 65498.23, \n",
    "                   \"final_rmse\": 61577.52\n",
    "                  }\n",
    "\n",
    "X = np.arange(len(baseline))\n",
    "ax = plt.subplot(111)\n",
    "ax.bar(X, baseline.values(), width=0.2, align='center', color=cm.Pastel1(0))\n",
    "ax.bar(X+0.2, less_features.values(), width=0.2, align='center', color=cm.Pastel1(1))\n",
    "ax.legend(('Baseline','Less features'))\n",
    "plt.xticks(X, baseline.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in all cases the dropped features resulted in higher accuracy error when cross validation threshold was 0.1. Choosing a smaller threshold of 0.05 we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "less_features2 = {\"lin_rmse\": 72528.01, \n",
    "                   \"poly_rmse\": 65024.48, \n",
    "                   \"tree_cv\": 84517.32, \n",
    "                   \"lin_cv\": 72561.17, \n",
    "                   \"forest_cv\": 64665.28, \n",
    "                   \"final_rmse\": 61309.45\n",
    "                  }\n",
    "\n",
    "X = np.arange(len(baseline))\n",
    "ax = plt.subplot(111)\n",
    "ax.bar(X, baseline.values(), width=0.2, align='center', color=cm.Pastel1(0))\n",
    "ax.bar(X+0.2, less_features.values(), width=0.2, align='center', color=cm.Pastel1(1))\n",
    "ax.bar(X+0.4, less_features2.values(), width=0.2, align='center', color=cm.Pastel1(2))\n",
    "ax.legend(('Baseline','Less features (0.1)', 'Less features (0.05)'), fontsize='small')\n",
    "plt.xticks(X, baseline.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that having less features does not help, especially when the features that were removed were the basis of derived features that were added to the original pipeline before prepropcessing (e.g. `households`, `total_bedrooms`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Using alternative preprocessing options\n",
    "\n",
    "### `SimpleImputer` strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "imputer.fit(housing_num)\n",
    "\n",
    "X = imputer.transform(housing_num)\n",
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Bike sharing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
